{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ab5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0320b",
   "metadata": {},
   "source": [
    "### Get the data and process\n",
    "- This is the Mysterious island found in Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e64a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1130711\n",
      "Unique Characters: 85\n"
     ]
    }
   ],
   "source": [
    "## Reading and processing text\n",
    "with open('data/mysterious_island.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "\n",
    "# Get the index of 'THE MYSTERIOUS ISLAND' or 'The Mysterious Island'\n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND') \n",
    "# Get the index of 'End of the Project Gutenberg'\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "# Set text to the text between start and end idx.\n",
    "text = text[start_indx:end_indx] \n",
    "# Get the unique set of characters.\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))\n",
    "assert(len(text) == 1130711)\n",
    "assert(len(char_set) == 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650c1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76393bdb",
   "metadata": {},
   "source": [
    "### Tokenize and get other helpers\n",
    "- We do this manually since everything is character based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a445114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
      "[37 47 40 29 42 32]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "# The universe of words\n",
    "chars_sorted = sorted(char_set)\n",
    "\n",
    "# Effectively, these maps are the tokenizer.\n",
    "# Map each char to a unique int\n",
    "char2int = {char: i for i, char in enumerate(chars_sorted)} \n",
    "# Reverse\n",
    "int2char = np.array(chars_sorted) \n",
    "\n",
    "# Tokenize the entire corpus\n",
    "text_encoded = np.array([char2int[char] for char in text], dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(int2char[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720cd752",
   "metadata": {},
   "source": [
    "#### Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2743a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
      "[37 47 40 29 42 32]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(int2char[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367e733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(\n",
    "    np.array_equal(\n",
    "    text_encoded[:15],\n",
    "        [48, 36, 33, 1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c418ca0",
   "metadata": {},
   "source": [
    "### Process the data and get the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f429dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "# Break up the data into chunks of size 41. This will be used to get (x, y) pairs.\n",
    "text_chunks = [list(text_encoded[i:i+chunk_size]) for i in range(0, len(text_encoded)-41)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e329fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the text chunk at index idx.\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        # Return (x, y) where x has length 40 and y has length 40.\n",
    "        # y should be x shifted by 1 time.\n",
    "        return (text_chunk[:-1],text_chunk[1:])\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71328555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40]) torch.Size([40])\n",
      "Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "\n",
      "torch.Size([40]) torch.Size([40])\n",
      "Input (x): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "Target (y): 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    # 40 characters for source and target\n",
    "    print(seq.shape, target.shape)\n",
    "    print('Input (x):', repr(''.join(int2char[seq])))\n",
    "    print('Target (y):', repr(''.join(int2char[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb989c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a881b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed0b2f",
   "metadata": {},
   "source": [
    "### Write the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4cbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        # Set to an embedding layer of vocab_size by embed_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embed_dim\n",
    "        ) \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        # Set to an LSTM with x having embed_dim and h dimension rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_dim,\n",
    "            rnn_hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Make a linear layer from rnn_hidden_size to vocab_size\n",
    "        # This will be used to get the yt for each xt\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, text, hidden=None, cell=None):\n",
    "        # Get the embeddings for text\n",
    "        out = self.embedding(text)\n",
    "        \n",
    "        # Pass out, hidden and cell through the rnn\n",
    "        if hidden is not None:\n",
    "            out, (hidden, cell) = self.rnn(out, (hidden, cell)) \n",
    "        else:\n",
    "            out, (hidden, cell) = self.rnn(out) \n",
    "        \n",
    "        # Pass out through fc\n",
    "        out = self.fc(out) \n",
    "        \n",
    "        return out, (hidden, cell)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size) \n",
    "        cell =  torch.zeros(1, batch_size, self.rnn_hidden_size) \n",
    "        return hidden.to(device), cell.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33380607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(85, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(int2char)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f47f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.4368\n",
      "Epoch 100 loss: 1.7288\n",
      "Epoch 200 loss: 1.4757\n",
      "Epoch 300 loss: 1.4383\n",
      "Epoch 400 loss: 1.3761\n",
      "Epoch 500 loss: 1.3576\n",
      "Epoch 600 loss: 1.3231\n",
      "Epoch 700 loss: 1.3780\n",
      "Epoch 800 loss: 1.2898\n",
      "Epoch 900 loss: 1.2814\n",
      "Epoch 1000 loss: 1.2473\n",
      "Epoch 1100 loss: 1.2786\n",
      "Epoch 1200 loss: 1.2971\n",
      "Epoch 1300 loss: 1.2105\n",
      "Epoch 1400 loss: 1.2104\n",
      "Epoch 1500 loss: 1.2749\n",
      "Epoch 1600 loss: 1.2072\n",
      "Epoch 1700 loss: 1.2126\n",
      "Epoch 1800 loss: 1.2599\n",
      "Epoch 1900 loss: 1.1995\n",
      "Epoch 2000 loss: 1.1940\n",
      "Epoch 2100 loss: 1.2404\n",
      "Epoch 2200 loss: 1.2516\n",
      "Epoch 2300 loss: 1.1620\n",
      "Epoch 2400 loss: 1.2366\n",
      "Epoch 2500 loss: 1.2003\n",
      "Epoch 2600 loss: 1.1787\n",
      "Epoch 2700 loss: 1.1795\n",
      "Epoch 2800 loss: 1.2657\n",
      "Epoch 2900 loss: 1.1573\n",
      "Epoch 3000 loss: 1.1851\n",
      "Epoch 3100 loss: 1.1391\n",
      "Epoch 3200 loss: 1.2206\n",
      "Epoch 3300 loss: 1.1572\n",
      "Epoch 3400 loss: 1.1195\n",
      "Epoch 3500 loss: 1.1588\n",
      "Epoch 3600 loss: 1.1817\n",
      "Epoch 3700 loss: 1.1273\n",
      "Epoch 3800 loss: 1.1181\n",
      "Epoch 3900 loss: 1.1720\n",
      "Epoch 4000 loss: 1.1684\n",
      "Epoch 4100 loss: 1.1902\n",
      "Epoch 4200 loss: 1.1553\n",
      "Epoch 4300 loss: 1.1830\n",
      "Epoch 4400 loss: 1.1918\n",
      "Epoch 4500 loss: 1.1718\n",
      "Epoch 4600 loss: 1.1591\n",
      "Epoch 4700 loss: 1.1435\n",
      "Epoch 4800 loss: 1.1344\n",
      "Epoch 4900 loss: 1.1633\n",
      "Epoch 5000 loss: 1.1481\n",
      "Epoch 5100 loss: 1.1330\n",
      "Epoch 5200 loss: 1.1162\n",
      "Epoch 5300 loss: 1.1441\n",
      "Epoch 5400 loss: 1.1874\n",
      "Epoch 5500 loss: 1.0875\n",
      "Epoch 5600 loss: 1.1637\n",
      "Epoch 5700 loss: 1.1912\n",
      "Epoch 5800 loss: 1.1774\n",
      "Epoch 5900 loss: 1.1413\n",
      "Epoch 6000 loss: 1.1902\n",
      "Epoch 6100 loss: 1.1469\n",
      "Epoch 6200 loss: 1.1355\n",
      "Epoch 6300 loss: 1.1696\n",
      "Epoch 6400 loss: 1.1142\n",
      "Epoch 6500 loss: 1.1520\n",
      "Epoch 6600 loss: 1.1456\n",
      "Epoch 6700 loss: 1.1800\n",
      "Epoch 6800 loss: 1.1412\n",
      "Epoch 6900 loss: 1.1591\n",
      "Epoch 7000 loss: 1.1568\n",
      "Epoch 7100 loss: 1.1318\n",
      "Epoch 7200 loss: 1.1569\n",
      "Epoch 7300 loss: 1.1858\n",
      "Epoch 7400 loss: 1.1890\n",
      "Epoch 7500 loss: 1.1432\n",
      "Epoch 7600 loss: 1.1235\n",
      "Epoch 7700 loss: 1.1117\n",
      "Epoch 7800 loss: 1.0790\n",
      "Epoch 7900 loss: 1.1368\n",
      "Epoch 8000 loss: 1.1689\n",
      "Epoch 8100 loss: 1.1475\n",
      "Epoch 8200 loss: 1.1191\n",
      "Epoch 8300 loss: 1.0900\n",
      "Epoch 8400 loss: 1.1583\n",
      "Epoch 8500 loss: 1.1248\n",
      "Epoch 8600 loss: 1.1349\n",
      "Epoch 8700 loss: 1.0960\n",
      "Epoch 8800 loss: 1.1480\n",
      "Epoch 8900 loss: 1.1639\n",
      "Epoch 9000 loss: 1.1044\n",
      "Epoch 9100 loss: 1.1603\n",
      "Epoch 9200 loss: 1.1705\n",
      "Epoch 9300 loss: 1.2047\n",
      "Epoch 9400 loss: 1.1655\n",
      "Epoch 9500 loss: 1.2039\n",
      "Epoch 9600 loss: 1.0823\n",
      "Epoch 9700 loss: 1.1125\n",
      "Epoch 9800 loss: 1.1604\n",
      "Epoch 9900 loss: 1.0942\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 10000\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    \n",
    "    # Get the next batch from seq_dl\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "        \n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    # Pass through the model\n",
    "    logits, _ = model(seq_batch, hidden, cell)\n",
    "    # Get the loss\n",
    "    loss += criterion(logits.view(logits.shape[0] * logits.shape[1], -1),\n",
    "            target_batch.view(-1).long()) \n",
    "        \n",
    "    # Back propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    \n",
    "    # Get the value in the tensor loss\n",
    "    loss = loss.item() \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f398f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[0.0159, 0.1173, 0.8668]])\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "logits = torch.tensor([[-1.0, 1.0, 3.0]])\n",
    "\n",
    "# Get the probabilities for these logits\n",
    "print('Probabilities:', Categorical(logits=logits).probs)\n",
    "\n",
    "# Get a Categorical random variable with the above probabilities for each of the classes\n",
    "m = Categorical(logits=logits)\n",
    "# Generate 10 things\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614fb236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island in their day and the diffactured for a\n",
      "clump of turn of trees, and the shore between the base in the islet, was refeind that by the\n",
      "fire from their circumstances neither a\n",
      "ship up name on an opening began to drew himself even either to warn it, making again streaks than crize, and\n",
      "its warves of the paper of the phown were mingled. At the engineer, for, taking it in his companions had again sailed always although to take to the other clamesâ€™ heartle,\n",
      "and took that this lucky could arranged in th\n"
     ]
    }
   ],
   "source": [
    "def random_sample(\n",
    "    model,\n",
    "    starting_str, \n",
    "    len_generated_text=500, \n",
    "):\n",
    "\n",
    "    # Encode starting string into a tensor using char2str\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    \n",
    "    encoded_input = encoded_input.unsqueeze(0) \n",
    "    \n",
    "    generated_str = starting_str\n",
    "\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    \n",
    "    hidden = hidden.to(device)\n",
    "    \n",
    "    cell = cell.to(device)\n",
    "        \n",
    "    # Build up the starting hidden and cell states\n",
    "    for c in range(len(starting_str)-1):\n",
    "        # Feed each letter 1 by 1 and then get the final hidden state\n",
    "        out = encoded_input[0][c:c+1].unsqueeze(0) \n",
    "        # Pass out through, note we update hidden and cell and use them again\n",
    "        _, (hidden, cell) = model(out, hidden, cell) \n",
    "    \n",
    "    # Get the last char; note we did not do go to the last char above\n",
    "    last_char = encoded_input[0][-1].unsqueeze(0).unsqueeze(0) \n",
    "    # Generate chars one at a time, add them to generated_str\n",
    "    # Do this over and over until you get the desired length\n",
    "    for i in range(len_generated_text):\n",
    "        \n",
    "        # Use hidden and cell from the above.\n",
    "        # Use last_char, which will be updated over and over.\n",
    "        logits, (hidden, cell) = model(last_char, hidden, cell)\n",
    "        \n",
    "        # Get the logits\n",
    "        logits = logits.squeeze(0) \n",
    "        \n",
    "        m = Categorical(logits=logits) #random variable with probabilities based on the softmax of the logits\n",
    "        \n",
    "        # Generate from m 1 char\n",
    "        last_char = torch.tensor(m.sample().item()).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # Add the generated char to generated_str\n",
    "        generated_str += int2char[last_char.item()]\n",
    "        \n",
    "    return generated_str\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model.to(device)\n",
    "print(random_sample(model, starting_str='The island'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
